[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=64
subdivisions=4
width=768
height=448
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.00002
burn_in=1000
max_batches = 500200
policy=steps
steps=400000,450000
scales=.1,.1

#mosaic=1

[convolutional]          # 0
batch_normalize=1
filters=32
size=3
stride=2
pad=1
activation=leaky

[convolutional]          # 1
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=leaky

[convolutional]          # 2
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[route]                  # 3
layers=-1
#groups=2
#group_id=1

[convolutional]          # 4
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

[convolutional]          # 5
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

[route]                  # 6
layers = -1,-2

[convolutional]          # 7
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[route]                  # 8
layers = -6,-1

[convolutional]          # 9
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[route]                  # 10
layers=-1
#groups=2
#group_id=1

[convolutional]          # 11
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

[convolutional]          # 12
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

[route]                  # 13
layers = -1,-2

[convolutional]          # 14
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[route]                  # 15
layers = -6,-1

[maxpool]                # 16
size=2
stride=2

[convolutional]          # 17
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[route]                  # 18
layers=-1
#groups=2
#group_id=1

[convolutional]          # 19
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[convolutional]          # 20
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[route]                  # 21
layers = -1,-2

[convolutional]          # 22
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[route]                  # 23
layers = -6,-1

[maxpool]                # 24
size=2
stride=2

[convolutional]          # 25
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[route]                  # 26
layers=-1
#groups=2
#group_id=1

[convolutional]          # 27
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[convolutional]          # 28
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[route]                  # 29
layers = -1,-2

[convolutional]          # 30
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[route]                  # 31
layers = -6,-1

[maxpool]                # 32
size=2
stride=2

[convolutional]          # 33
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

##################################

[convolutional]          # 34
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]          # 35
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[convolutional]          # 36
size=1
stride=1
pad=1
filters=30
activation=linear

[yolo]                   # 37
mask = 6,7,8
anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401
classes=5
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
scale_x_y = 1.05
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=diounms
beta_nms=0.6
# iou_thresh_kind=ciou

[route]                  # 38
layers = -4

[convolutional]          # 39
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[upsample]               # 40
stride=2

[route]                  # 41
layers = -1, 30

[convolutional]          # 42
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[convolutional]          # 43
size=1
stride=1
pad=1
filters=30
activation=linear

[yolo]                   # 44
mask = 3,4,5
anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401
classes=5
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
scale_x_y = 1.05
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=diounms
beta_nms=0.6
# iou_thresh_kind=ciou

[route]                  # 45
layers = -3

[convolutional]          # 46
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[upsample]               # 47
stride=2

[route]                  # 48
layers = -1, 22

[convolutional]          # 49
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[convolutional]          # 50
size=1
stride=1
pad=1
filters=30
activation=linear

[yolo]                   # 51
mask = 0,1,2
anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401
classes=5
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
scale_x_y = 1.05
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=diounms
beta_nms=0.6
#iou_thresh_kind=ciou

[route]                  # 52                  
layers=-17               # 35    

[convolutional]          # 53  第一层YOLO层对应的特征向量
size=1
stride=1
pad=1
filters=128
activation=linear 

[route]                  # 54
layers=-12               # 42

[convolutional]          # 55  第二层YOLO层对应的特征向量
size=1
stride=1
pad=1
filters=128
activation=linear 

[route]                  # 56
layers=-7                # 49

[convolutional]          # 57  第三层YOLO层对应的特征向量
size=1
stride=1
pad=1
filters=128
activation=linear 
