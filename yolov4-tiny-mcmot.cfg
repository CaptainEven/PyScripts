[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=128  # 64
subdivisions=1
width=768  # 416
height=448  # 416
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.00261
burn_in=1000
max_batches = 500200
policy=steps
steps=400000,450000
scales=.1,.1

[convolutional]               # 0
batch_normalize=1
filters=32
size=3
stride=2
pad=1
activation=leaky

[convolutional]               # 1
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=leaky

[convolutional]               # 2
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[route_lhalf]                 # 3    
layers=-1

[convolutional]               # 4
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

[convolutional]               # 5
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

[route]                       # 6
layers = -1,-2

[convolutional]               # 7
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[route]                       # 8
layers = -6,-1

[maxpool]                     # 9
size=2
stride=2

[convolutional]               # 10
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[route_lhalf]                 # 11
layers=-1

[convolutional]               # 12
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[convolutional]               # 13
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[route]                       # 14
layers = -1,-2

[convolutional]               # 15
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[route]                       # 16
layers = -6,-1

[maxpool]                     # 17
size=2
stride=2

[convolutional]               # 18
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[route_lhalf]                 # 19
layers=-1

[convolutional]               # 20
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[convolutional]               # 21
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[route]                       # 22
layers = -1,-2

[convolutional]               # 23
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[route]                       # 24
layers = -6,-1

[maxpool]                     # 25
size=2
stride=2

[convolutional]               # 26
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

##################################

[convolutional]              # 27
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]              # 28
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[convolutional]              # 29
size=1
stride=1
pad=1
filters=255
activation=linear

[yolo]                       # 30
mask = 3,4,5
anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319
classes=80
num=6
jitter=.3
scale_x_y = 1.05
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
ignore_thresh = .7
truth_thresh = 1
random=0
nms_kind=greedynms
beta_nms=0.6

[route]                      # 31
layers = -4

[convolutional]              # 32
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[upsample]                   # 33
stride=2

[route]                      # 34
layers = -1, 23

[convolutional]              # 35
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[convolutional]              # 36
size=1
stride=1
pad=1
filters=255
activation=linear

[yolo]                       # 37
mask = 1,2,3
anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319
classes=80
num=6
jitter=.3
scale_x_y = 1.05
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
ignore_thresh = .7
truth_thresh = 1
random=0
nms_kind=greedynms
beta_nms=0.6
